using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Text.RegularExpressions;

using Nemerle.Collections;
using Nemerle.Compiler;
using Nemerle.Imperative;
using Nemerle.Utility;

using PExpr  = Nemerle.Compiler.Parsetree.PExpr;
using TP     = Nemerle.Completion2.ScanTokenType;
using C      = Nemerle.Completion2.ScanTokenColor;
using TR     = Nemerle.Completion2.ScanTokenTriggers;
using SCG    = System.Collections.Generic;
using NQueue = Nemerle.Collections.Queue;

namespace Nemerle.Completion2
{
  public module LPontEx
  {
    public StartPoint(this loc : Location) : LPoint { LPoint(loc.Line,    loc.Column) }
    public EndPoint  (this loc : Location) : LPoint { LPoint(loc.EndLine, loc.EndColumn) }
    public ToPoints  (this loc : Location) : LPoint * LPoint
    {
      (loc.StartPoint(), loc.EndPoint())
    }
  }
  
  [Record]
  public struct LPoint : IEquatable[LPoint], IComparable[LPoint]
  {
    public Line   : int;
    public Column : int;
    
    public static @==(x : LPoint, y : LPoint) : bool { x.Equals(y) }
    public static @!=(x : LPoint, y : LPoint) : bool { !x.Equals(y) }
    public static @< (x : LPoint, y : LPoint) : bool { x.CompareTo(y) <  0 }
    public static @<=(x : LPoint, y : LPoint) : bool { x.CompareTo(y) <= 0 }
    public static @> (x : LPoint, y : LPoint) : bool { x.CompareTo(y) >  0 }
    public static @>=(x : LPoint, y : LPoint) : bool { x.CompareTo(y) >= 0 }
    
    // TODO: Надо добавить проверку перехода за конец/начало строки.
    // Для этого нужно чтобы LPoint ссылался на source (имел доступ к буферу редактора).
    public Increment() : LPoint { LPoint(Line, Column + 1)  }
    public Decrement() : LPoint { LPoint(Line, Column - 1)  }
    
    public CompareTo(other : LPoint) : int
    {
      if (Line == other.Line) Column - other.Column
      else                    Line - other.Line;
    }
    
    [Nemerle.OverrideObjectEquals]
	  public Equals(other : LPoint) : bool implements IEquatable[LPoint].Equals
	  {
      Line == other.Line && Column == other.Column
	  }
	  
	  public override GetHashCode() : int { Line ^ Column }
	  
	  public override ToString() : string { $"$Line:$Column" }
  }

  public class ScanLexer : LexerString
  {
    /// Nullable!!!
    mutable _hoverHighlightedLocations : Hashtable[int, list[Location * int]];
    mutable _permanentHighlights       : list[Hashtable[int, list[Location * int]]] = [];
    mutable _env                       : GlobalEnv;
    mutable _typeBuilder               : TypeBuilder;
    mutable _last_line                 : int;
    mutable _last_col                  : int;
    mutable _onPreprocessor            : bool;
    mutable _keepDollar                : bool;
    mutable _bracketCount              : int;
    mutable _recursiveStringCount      : int;
    mutable _quotationCount            : int;
    mutable _identifiers               : list[string] = [];
    mutable _tokenInfo                 : ScanTokenInfo;
            _pendingTokens             : NQueue[ScanTokenInfo] = NQueue();

    static _keywords                   : Dictionary[string,string] = Dictionary();
    static _quotationTypes             : Dictionary[string,string] = Dictionary();

    static this()
    {
      foreach (name in ["object", "int", "string", "void", "bool", "list", "byte", "float", "uint", "char", 
       "ulong", "ushort", "decimal", "sbyte", "short", "double", "long", "get", "set", "default",
       "add", "remove"])
	     _keywords.Add(name, name);

      foreach (name in ["ttype",  "fundecl", "case",  "parameter", "decl"])
        _quotationTypes.Add(name, name);
    }

    public this(manager : ManagerClass)
    {
      base(manager, "", Location());
      assert2(manager.CoreEnv != null);
      Keywords = manager.CoreEnv.Keywords;
    }

    public SetFileName(fileName : string) : void
    {
      file_idx = Location.GetFileIndex(IO.Path.GetFullPath(fileName));
    }

    public SetLine(
      lineNumber  : int,
      line    : string,
      offset    : int,
      env     : GlobalEnv,
      typeBuilder : TypeBuilder
    )
      : void
    {
      base.reader    = line;
      base.pos       = offset;
      base.line      = lineNumber;
      //phantom: if you notice any lexer crashes, write me
      //base.line      = 1;
      base.col       = 1;
      base.isPendingChar   = false;
      base.white_beginning = true;
      base.eating_stack  = Stack();
      base.eating_now    = 0;

      _env = env ?? Manager.CoreEnv;
      
      when (typeBuilder != null)
      _typeBuilder = typeBuilder;
      
      _onPreprocessor     = false;
      _tokenInfo = ScanTokenInfo();
      _bracketCount     = -1;
      _recursiveStringCount = -1;
      _quotationCount     = -1;

      _tokenInfo.IsEndOfLine = eol();

      when (_identifiers.Length != 0)
      _identifiers = [];

      unless (_env == null)
        Keywords = _env.Keywords;
    }

    skip() : void
    {
      ignore(read());
    }

    eol() : bool
    {
      pos >= reader.Length
    }

    step_back() : void
    {
      pos--;
      col--;
    }

    back_to_start() : void
    {
      col = _last_col;
      pos = col - 1;
    }

    peek_next() : char
    {
      if (pos+1 < reader.Length) reader[pos+1] else '\0'
    }

    skip_to_end() : void
    {
      pos = reader.Length;
      col = pos + 1;
    }

    skip_whitespace() : void
    {
      def loop() 
      {
      match (peek()) 
      {
      | ' ' | '\t' | '\r' | '\n' => skip(); loop();
      | '\0' | _ => ()
      }
      }

      loop();
    }

    CurrentValue : string
    {
      get { reader.Substring(_last_col - 1, col - _last_col) }
    }

    private GetWhiteSpaceToken() : Token
    {
      skip_whitespace();
      Token.WhiteSpace(CurrentValue);
    }

    private FindEndOfComment() : Token.Comment
    {
      def idx = reader.IndexOf("*/", pos);

      if (idx >= 0)
      {
      _tokenInfo.State &= ~ScanState.Comment;
      pos = idx + 2;
      col = pos + 1;
      }
      else
      {
      _tokenInfo.State |=  ScanState.Comment;
      skip_to_end();
      }

      Token.Comment(CurrentValue);
    }

    private GetCommentToken() : Token
    {
      skip();

      match (peek())
      {
      | '/' => 

      skip_to_end();
      Token.Comment(CurrentValue);

      | '*' => 

      skip();
      FindEndOfComment()

      | _   => step_back(); null
      }
    }

    private SColor(isEx : bool) : C
    {
      if    (_tokenInfo.IsMultiLineString) if (isEx) C.VerbatimStringEx  else C.VerbatimString
      else if (_tokenInfo.IsRecursiveString) if (isEx) C.RecursiveStringEx else C.RecursiveString
      else                   if (isEx) C.StringEx      else C.String
    }

    private GetStringToken() : Token * ScanTokenType * ScanTokenColor * ScanTokenTriggers
    {
      when (_tokenInfo.IsDollar && _bracketCount < 0)
      _bracketCount = _tokenInfo.BracketCount;

      when (_tokenInfo.IsRecursiveString  && _recursiveStringCount < 0)
      _recursiveStringCount = _tokenInfo.RecursiveCount;

      def getDollarContent() 
      {
      def loop()
      {
        def ch = read();

        match (ch)
        {
        | '(' => 

        _bracketCount++;
        _tokenInfo.BracketCount = _bracketCount;
        loop();

        | ')' => 

        _bracketCount--;
        _tokenInfo.BracketCount = _bracketCount;

        unless (_bracketCount == 0)
          loop();

        | '\\' when !_tokenInfo.IsMultiLineString && peek() == '"'
        | '"'  when  _tokenInfo.IsMultiLineString && peek() == '"' => 

        skip();
        loop();

        | '"' when !_tokenInfo.IsRecursiveString =>

        _tokenInfo.State &= ~(ScanState.String | ScanState.MultiLineString);

        | '#' when _tokenInfo.IsRecursiveString && peek() == '>' => 

        _recursiveStringCount--;
        _tokenInfo.RecursiveCount = _recursiveStringCount;

        if (_recursiveStringCount == 0)
          _tokenInfo.State &= ~(ScanState.String | ScanState.RecursiveString);
        else
        {
          skip();
          loop();
        }

        | '\0' => ()
        | _  => loop()
        }
      }

      def c = SColor(true);

      loop();
      (Token.StringLiteral(CurrentValue), TP.String, c, TR.None)
      }

      if (_bracketCount > 0)
      {
        getDollarContent()
      }
      else match (peek())
      {
      | '"' when _tokenInfo.IsMultiLineString && peek_next() == '"' => 

        repeat (2) skip();
        (Token.StringLiteral(CurrentValue), TP.String, SColor(true), TR.None)

      | '"' when !_tokenInfo.IsRecursiveString => 

        skip();

        def c = SColor(false);

        _tokenInfo.State &= ~(ScanState.String | ScanState.MultiLineString);
        (Token.StringLiteral(CurrentValue), TP.String, c, TR.None)

      | '#' when _tokenInfo.IsRecursiveString && peek_next() == '>' => 

      repeat (2) skip();

      _recursiveStringCount--;
      _tokenInfo.RecursiveCount = _recursiveStringCount;

      if (_recursiveStringCount == 0)
      {
        def c = SColor(false);

         _tokenInfo.State &= ~(ScanState.String | ScanState.RecursiveString);
        (Token.StringLiteral(CurrentValue), TP.String, c, TR.None)
      }
      else
      {
        GetStringToken();
      }

      | '<' when _tokenInfo.IsRecursiveString && peek_next() == '#' => 

      repeat (2) skip();

      _recursiveStringCount++;
      _tokenInfo.RecursiveCount = _recursiveStringCount;

      (Token.StringLiteral(CurrentValue), TP.String, SColor(false), TR.None)

      | '\\' when !_tokenInfo.IsMultiLineString =>

      skip();

      def opt = Manager.Options.ThrowOnError;

      Manager.Options.ThrowOnError = true;

      def tok = try
      {
        _ = escape_value(read(), null);
        (Token.StringLiteral(CurrentValue), TP.String, SColor(true), TR.None)
      }
      catch
      {
        _ => (Token.StringLiteral(CurrentValue), TP.String, SColor(false), TR.None)
      }

      Manager.Options.ThrowOnError = opt;

      tok;

      | '{' when peek_next() == '{'    => 

      repeat (2) skip();
      (Token.StringLiteral(CurrentValue), TP.String, SColor(false), TR.None)

      | '{' when char.IsDigit(peek_next()) => 

      def loop()
      {
        match (peek())
        {
        | '$' when _tokenInfo.IsDollar
        | '\0' | '"' | '{' => ();   false;
        | '}'        => skip(); true;
        | _        => skip(); loop();
        }
      }

      skip();
      def ex = loop();
      (Token.StringLiteral(CurrentValue), TP.String, SColor(ex), TR.None)

      | '$' when _tokenInfo.IsDollar && peek_next() == '(' => 

      skip();
      getDollarContent();

      | '$' when _tokenInfo.IsDollar && IsIdBeginning(peek_next()) => 

      def loop()
      {
        def ch = peek();

        when (IsIdBeginning(ch) || char.IsDigit(ch))
        {
        skip();
        loop();
        }
      }

      repeat (2) skip();
      loop();
      (Token.StringLiteral(CurrentValue), TP.String, SColor(true), TR.None)

      | _   => 

      def loop()
      {
        skip();
        match (peek())
        {
        | '"'
        | '\\'
        | '{'
        | '$' when _tokenInfo.IsDollar
        | '#' when _tokenInfo.IsRecursiveString
        | '<' when _tokenInfo.IsRecursiveString
        | '\0' => ()
        | _ => loop()
        }
      }

      loop();
      (Token.StringLiteral(CurrentValue), TP.String, SColor(false), TR.None)

      }
    }

    private GetPreprocessorToken() : Token
    {
      mutable last_col;

      def readWord() : string 
      {
        while (Char.IsWhiteSpace(peek()))
          skip();

        last_col = col;

        for (mutable c = peek(); IsIdBeginning(c) || Char.IsDigit(c); c = peek())
          skip();

        reader.Substring(last_col - 1, col - last_col);
      }

      match (readWord())
      {
      | "if" | "elif" | "else" | "endif"
      | "error"  | "warning"
      | "region" | "endregion"
      | "define" | "undef" => last_col = col;
      | "line"       => 
        last_col = col;
        when (readWord() == "default")
          last_col = col

      | "pragma"       => 
        last_col = col;

        match (readWord())
        {
        | "indent"  => last_col = col;
        | "warning" => last_col = col;

          match (readWord())
          {
          | "disable" | "restore" => last_col = col
          | _ => ()
          }
        | _ => ()
        }
        | _          => ()
        }

        col = last_col;
        pos = col - 1;

        Token.Keyword(CurrentValue);
    }

    GetIdentifierColor(name : string) : ScanTokenColor
    {
      def getColor()
      {
      def lookup()
      {
        def ids = if (_identifiers.Length > 1) _identifiers.Rev() else _identifiers;
        if (_env == null) C.Identifier
        else match (_env.LookupType(ids, _typeBuilder, -1))
        {
          | Some(ti) =>
            if      (ti.IsEnum)      C.UserTypeEnum
            else if (ti.IsDelegate)  C.UserTypeDelegate
            else if (ti.IsValueType) C.UserTypeValueType
            else if (ti.IsInterface) C.UserTypeInterface
            else                     C.UserType

          | None => C.Identifier
        }
      }

      if (_typeBuilder != null && _typeBuilder.IsEnum && _last_col > 1)
      {
        def line = reader.Substring(0, _last_col - 1).TrimEnd(' ', '\t');

        _debug(line);

        if (line.Length > 0 && line[line.Length-1] == '|')
        C.Identifier
        else
        lookup();
      }
      else
        lookup();
      }

      match (_tokenInfo.Token)
      {
      | Operator(".") when _identifiers.Length == 0 => C.Identifier
      | Operator(".") => _identifiers ::= name;   getColor();
      | _       => _identifiers = name :: []; getColor();
      }
    }

    _Debug[T](o : T) : void
    {
      _ = o.ToString();
    }

    private GetBaseToken() : Token * ScanTokenType * ScanTokenColor * ScanTokenTriggers
    {
      _keepDollar = false;

      try
      {
      def last_col = col;

      def tok = base.GetToken();

      def (tp, color, trigger) = match (tok)
      {
      | Identifier(nm) when _keywords.ContainsKey(nm)
      | Keyword("if") 
      | Keyword("else")  => (TP.Keyword,  C.Keyword,  TR.MatchBraces)
      | Keyword          => (TP.Keyword,  C.Keyword,  TR.None)
      | Identifier(name) => 

        if (_tokenInfo.IsQuotationStart && _quotationTypes.ContainsKey(name.ToLower()) && 
        {
          def s = reader.Substring(pos).TrimStart(' ', '\t');
          s.Length > 0 && s[0] == ':'
        })
        {
        (TP.Keyword,  C.Keyword,  TR.None)
        }
        else
        (TP.Identifier, GetIdentifierColor(name), TR.None)

      | IdentifierToComplete => (TP.Identifier, C.Identifier, TR.None)
      | Comma                => (TP.Operator,   C.Operator,   TR.ParameterNext)
      | Semicolon            => (TP.Operator,   C.Operator,   TR.None)
      | Operator(nm)         => 

        // This fixes the eating comment following the operator ( :/* */ ).
        //
        when (nm.Length < col - last_col)
        {
          col = last_col + nm.Length;
          pos = col - 1;
        }

        match (nm)
        {
        | "."                => 

        match (_tokenInfo.Token)
        {
        | Identifier => ()
        | _      => when (_identifiers.Length > 0) _identifiers = [];
        }

        (TP.Delimiter, C.Operator, TR.MemberSelect)

        | ".." when _tokenInfo.IsQuotation
        | "$"  when _tokenInfo.IsQuotation => (TP.Operator,  C.Keyword,  TR.None)
        | _                => (TP.Operator,  C.Operator, TR.None)
        }

      //| StringLiteral       => (TP.String,   C.String,   TR.None)
      | CharLiteral         => (TP.Literal,  C.String,   TR.None)
      | IntegerLiteral
      | FloatLiteral
      | DoubleLiteral
      | DecimalLiteral      => (TP.Literal,  C.Number,   TR.None)
      | Comment           => (TP.Comment,  C.Comment,  TR.None)
      | Indent
      | WhiteSpace        => (TP.WhiteSpace, C.Text,     TR.None)
      | BeginRound   /* (  */   => (TP.Operator,   C.Operator,   TR.MatchBraces | TR.ParameterStart)
      | EndRound     /* )  */   => (TP.Operator,   C.Operator,   TR.MatchBraces | TR.ParameterEnd)
      | BeginBrace   /* {  */
      | EndBrace     /* }  */
      | BeginSquare  /* [  */
      | EndSquare    /* ]  */   => (TP.Operator,   C.Operator,   TR.MatchBraces)
      | BeginQuote   /* <[ */   => 

        if (_tokenInfo.IsQuotation)
        {
        when (_quotationCount < 0)
          _quotationCount = _tokenInfo.QuotationCount;

        _quotationCount++;
        _tokenInfo.QuotationCount = _quotationCount;
        }
        else
        {
        _tokenInfo.State     |=  ScanState.Quotation;
        _tokenInfo.QuotationCount = 1;
        _quotationCount       = 1;
        }

        _tokenInfo.State |= ScanState.QuotationStart;

        (TP.Operator, C.Quotation, TR.MatchBraces)

      | EndQuote     /* ]> */   => 
        _tokenInfo.State &= ~ScanState.QuotationStart;

        when (_tokenInfo.IsQuotation)
        {
          when (_quotationCount < 0)
            _quotationCount = _tokenInfo.QuotationCount;

          _quotationCount--;
          _tokenInfo.QuotationCount = _quotationCount;

          unless (_quotationCount > 0)
          {
            _tokenInfo.State     &= ~ScanState.Quotation;
            _tokenInfo.QuotationCount = 0;
            _quotationCount       = 0;
          }
        }

        (TP.Operator, C.Quotation, TR.MatchBraces)

      | _             => (TP.Unknown,  C.Text,     TR.None)
      }

      (tok, tp, color, trigger)
      }
      catch
      {
      | _ => (Token.Identifier(""), TP.Unknown, C.Text, TR.None)
      }
    }

    public GetToken(prevState : ScanState) : ScanTokenInfo
    {
      unless (_pendingTokens.IsEmpty)
        return _pendingTokens.Dequeue();

      _tokenInfo = ScanTokenInfo();
      
      _tokenInfo.State       = prevState;
      _tokenInfo.ColorizeEnd = false;

      _last_line             = line;
      _last_col              = col;
      _keepDollar            = true;

      def resetQuotationStart = _tokenInfo.IsQuotationStart;

      (_tokenInfo.Token, _tokenInfo.Type, _tokenInfo.Color, _tokenInfo.Triggers)
        = 
        if (eol())
        {
          _tokenInfo.IsEndOfLine = eol();

          def color = if (_tokenInfo.IsMultiLineString)
          {
            _tokenInfo.ColorizeEnd = true;
            C.VerbatimString
          }
          else if (_tokenInfo.IsRecursiveString)
          {
            _tokenInfo.ColorizeEnd = true;
            C.RecursiveString
          }
          else if (_tokenInfo.IsQuotation)
          {
            _tokenInfo.ColorizeEnd = true;
            C.Quotation
          }
          else
          {
            when (_tokenInfo.IsString)
              _tokenInfo.State &= ~ScanState.String;
            C.Text
          }

          (Token.EndOfFile(), TP.Unknown, color, TR.None)
        }
        else if (_onPreprocessor)
        {
          skip_to_end();
          (Token.Identifier(""), TP.Unknown, C.Text, TR.None)
        }
        else if (_tokenInfo.IsComment)
        {
          (FindEndOfComment(), TP.Comment, C.Comment, TR.None)
        }
        else if (_tokenInfo.IsString)
        {
          GetStringToken()
        }
        else
        {
          def getString() 
          {
            match (peek())
            {
              | '"' =>

                _tokenInfo.State |= ScanState.String;
                skip();

              | '@' =>

                _tokenInfo.State |= (ScanState.String | ScanState.MultiLineString);
              repeat (2) skip();

              | '<' =>

                _recursiveStringCount = 1;
              _tokenInfo.RecursiveCount = _recursiveStringCount;
              _tokenInfo.State |= (ScanState.String | ScanState.RecursiveString);

              repeat (2) skip();

              | _ => throw InvalidOperationException()
            }

            (Token.StringLiteral(CurrentValue), TP.String, SColor(false), TR.None)
          }

          match (peek())
          {
            | ' ' | '\t' | '\n' | '\r' => 

              def tok = GetWhiteSpaceToken();
              (
                tok,
                TP.WhiteSpace,
                C.Text,
                {
                  def tok2 = (tok :> Token.WhiteSpace).value;
                  if (pos >= reader.Length && tok2 == " ")
                    match (_tokenInfo.Token)
                  {
                    | Keyword ("override")                              => TR.MemberSelect
                      | Keyword ("using") | Operator("|") | Operator(":") => TR.MemberSelect
                      | _                                                 => TR.None
                  }
                  else if (tok2 == " " && _tokenInfo.Token is Operator(":"))
                    TR.MemberSelect
                  else
                  TR.None
                }
              )

            | '#' when white_beginning => 
              _onPreprocessor = true;
              white_beginning = false;

              skip();

              if (pos >= reader.Length)
                (Token.Keyword("#"),   TP.Keyword, C.Preprocessor, TR.MemberSelect)
              else
              (GetPreprocessorToken(), TP.Keyword, C.Preprocessor, TR.None)

            | '/' => 
              def tok = GetCommentToken();

              if (tok != null) (tok, TP.Comment, C.Comment, TR.None)
              else             GetBaseToken();

            | '"'
            | '@' when peek_next() == '"'
            | '<' when peek_next() == '#' => 
              // HACK: We always colorize $.
              _tokenInfo.State |= ScanState.Dollar;

              getString();

            | '$' => 
              skip();
              skip_whitespace();

              match (peek())
              {
                | '\0' => 
                  _tokenInfo.State |= ScanState.Dollar;
                  (Token.Operator(CurrentValue), TP.Operator, C.Operator, TR.None)

                | '"' | '@' when peek_next() == '"'
                | '<' | '#' when peek_next() == '"' => 
                  _tokenInfo.State &= ~ScanState.BracketCounter;
                  _tokenInfo.State |=  ScanState.Dollar;
                  getString();

                | _ => back_to_start(); GetBaseToken();
              }

            | _   => GetBaseToken();
          }
        }

        when (!_keepDollar && _tokenInfo.IsDollar)
        {
          _tokenInfo.State &= ~ScanState.Dollar;
          _tokenInfo.BracketCount = 0;
          _bracketCount       = 0;
        }

        when (resetQuotationStart && !_tokenInfo.IsWhiteSpaceOrCommentType)
          _tokenInfo.State &= ~ScanState.QuotationStart;

        def convertColorToQuotationColor(color : ScanTokenColor)
        {
          | Text              => ScanTokenColor.QuotationText
          | Keyword           => ScanTokenColor.QuotationKeyword
          | Comment           => ScanTokenColor.QuotationComment
          | Identifier        => ScanTokenColor.QuotationIdentifier
          | String            => ScanTokenColor.QuotationString
          | Number            => ScanTokenColor.QuotationNumber
          | Operator          => ScanTokenColor.QuotationOperator
          | StringEx          => ScanTokenColor.QuotationStringEx
          | VerbatimString    => ScanTokenColor.QuotationVerbatimString
          | VerbatimStringEx  => ScanTokenColor.QuotationVerbatimStringEx
          | RecursiveString   => ScanTokenColor.QuotationRecursiveString
          | RecursiveStringEx => ScanTokenColor.QuotationRecursiveStringEx
          | UserType          => ScanTokenColor.QuotationUserType
          | UserTypeDelegate  => ScanTokenColor.QuotationUserTypeDelegate
          | UserTypeEnum      => ScanTokenColor.QuotationUserTypeEnum
          | UserTypeInterface => ScanTokenColor.QuotationUserTypeInterface
          | UserTypeValueType => ScanTokenColor.QuotationUserTypeValueType
          | _                 => _tokenInfo.Color
        }

        when (_tokenInfo.IsQuotation && !(_tokenInfo.Token is Token.BeginQuote))
          _tokenInfo.Color = convertColorToQuotationColor(_tokenInfo.Color);

        _tokenInfo.Token.Location = Location(file_idx, _last_line, _last_col, line, col);

        when(_tokenInfo.IsCommentType)
          CheckForSpecialComments(_tokenInfo);

        //TryFindSubtokens(_tokenInfo);
        
        CheckForHighlights(_tokenInfo);

        _tokenInfo
    }

    static InitSpecialCommentRegexes() : list[Regex * ScanTokenColor * bool]
    {
      def todoRegex = Regex(@"(\b(TODO)\b\s*:.*)", RegexOptions.Compiled);
      def bugRegex  = Regex(@"(\b(BUG)\b\s*:.*)",  RegexOptions.Compiled);
      def hackRegex = Regex(@"(\b(HACK)\b\s*:.*)", RegexOptions.Compiled);

      [
        // Usual mode comments
        (todoRegex, ScanTokenColor.CommentTODO,          false),
        (bugRegex,  ScanTokenColor.CommentBUG,           false),
        (hackRegex, ScanTokenColor.CommentHACK,          false),
        
        // Quotation mode comments
        (todoRegex, ScanTokenColor.QuotationCommentTODO, true),
        (bugRegex,  ScanTokenColor.QuotationCommentBUG,  true),
        (hackRegex, ScanTokenColor.QuotationCommentHACK, true)
      ]
    }

    #region Support for special comments
    
    static specialCommentRegexes : list[Regex * ScanTokenColor * bool] = InitSpecialCommentRegexes();

    CheckForSpecialComments(tokenInfo : ScanTokenInfo) : void
    { 
      def chooseColor(str, regexList)
      {
        match(regexList)
        {
          | (regex, color, isQuot) :: xs =>
              def m =  regex.Match(str);
              if(m.Success && tokenInfo.IsQuotation == isQuot)
                (m.Captures[0].Index, m.Captures[0].Length, color)
              else
                chooseColor(str, xs)
          | _ => (-1, -1, ScanTokenColor.Comment) // this color will be ignored.
        }
      }
      
      match(tokenInfo.Token)
      {
        | Comment(value) =>

            //TODO: Implement special comment in the middle of regular one, ie // regular >special one< regular again
            def commentOffset =  if(value.StartsWith("/*") || value.StartsWith("//")) 2;
                                 else 0;
            def commentWOBeginning =  if(commentOffset > 0) value.Substring(commentOffset) else value;
            
            def (idx, len, color)  = chooseColor(commentWOBeginning, specialCommentRegexes);

            when(idx != -1)
            {
              def pendingToken = tokenInfo.Clone();
              pendingToken.Token = Token.Comment(commentWOBeginning.Substring(idx, len));

              def loc = tokenInfo.Token.Location;
              // shrinking regular comment location
              tokenInfo.Token.Location = Location(loc, loc.Line, loc.Column, 
                loc.EndLine, loc.Column + commentOffset + idx);
              pendingToken.Color = color;
              pendingToken.Token.Location = Location(loc, loc.Line, 
                loc.Column + commentOffset + idx, loc.EndLine, loc.EndColumn);
              _pendingTokens.Enqueue(pendingToken);
            }

        | _ => () 
      }
    }

    #endregion

  _TryFindSubtokens(tokenInfo : ScanTokenInfo) : void
  {
    def tok = tokenInfo;
    match (tokenInfo.Type)
    {
      | ScanTokenType.String =>
        def loc = tokenInfo.Token.Location;
        def engine = Manager :> Engine;
        when (engine.IsProjectAvailable)
        {
          def proj = engine.Project;
          def exprs = proj.FindAllPExpr(loc);
          
          def toks = SCG.List();
          foreach (e in exprs)
          {
            | PExpr.Member(_obj, member) when member != null =>
              def newTok = tok.Clone();
              newTok.Color = ScanTokenColor.Identifier;
              newTok.Token = Token.Identifier(member.Location, member.ToString());
              toks.Add(newTok);
              
            | PExpr.Ref(name) when name != null =>
              def newTok = tok.Clone();
              newTok.Color = ScanTokenColor.Identifier;
              newTok.Token = Token.Identifier(name.Location, name.ToString());
              toks.Add(newTok);
                
            | PExpr.Tuple as tuple =>
              def newTok1 = tok.Clone();
              newTok1.Color = ScanTokenColor.Identifier;
              def l1 = tuple.Location.FromStart();
              newTok1.Token = Token.EndRound(Location(l1.FileIndex, l1.Line, l1.Column, l1.Line, l1.Column + 1));
              toks.Add(newTok1);
              
              def newTok2 = tok.Clone();
              newTok2.Color = ScanTokenColor.Identifier;
              //def l2 = tuple.Location.FromEnd();
              newTok2.Token = Token.EndRound(Location(l1.FileIndex, l1.Line, l1.Column - 1, l1.Line, l1.Column));
              toks.Add(newTok2);
              
            | _ => Debug.WriteLine($"Token in str: '$e'");
          }
          
          unless (toks.IsEmpty())
          {
            def tokLoc   = tokenInfo.Token.Location;

            // Отфильтровываем подсвечиваемые области пересекающиеся с текущим токеном
            // и преобразуем список в список типа (цвет * начало-диапазона * конец-диапазона).
            def overlappingRanges = (tokenInfo, tokLoc.StartPoint(), tokLoc.EndPoint()) 
              :: toks.Map(fun(t) { def loc = t.Token.Location; (t, loc.StartPoint(), loc.EndPoint()) });
                
            def inc(point) { point }
            def dec(point) { point }
            // Преобразуем пересекающиеся диапазоны в список диапазонов непересекающихся
            // между собой (идущий последовательно).
            def flatenRanges = Utils.Utils.RemoveOverlapping(overlappingRanges, inc, dec);
            
            def setTokenInfo(tokenInfo, (t, start, end))
            {
              def tokInf = if (tokenInfo : object == t) tokenInfo.Clone() else t;
              def loc = Location(tokLoc, start.Line, start.Column, end.Line, end.Column);
              tokInf.Token.Location = loc;
              tokInf
            }
            
            // Преобразуем диапазоны в токены с соответствующими Location-ами и добавляем
            // токены в список ожидаемых токенов (_pendingTokens).
            foreach (range in flatenRanges.Tail)
              _pendingTokens.Add(setTokenInfo(tokenInfo, range));
            
            // Первый токен приходится явно измнить, задав ему значения из головы списка.
            _ = setTokenInfo(tokenInfo, flatenRanges.Head);

            /*
            def f(t)
            {
              def loc = t.Token.Location;
              (t, (loc.Column, loc.Line), (loc.EndColumn, loc.EndLine))
            }
            def toks2 = toks.Map(f);
            def inc(point) { point }
            def dec(point) { point }
            def flatenRanges = Utils.Utils.RemoveOverlapping(overlappingRanges, inc, dec);
            //foreach(t in toks)
            //  _pendingTokens.Add(t)
            _ = flatenRanges;
            */
          }
        }
      
      | _ => ()
    }
    //this.Manager.Solver
  }
    
    CheckForHighlights(tokenInfo : ScanTokenInfo) : void
    {
      def tokLoc   = tokenInfo.Token.Location;
      def tocColor = tokenInfo.Color; 
      
      // TODO: Refactor _hoverHighlightedLocations usage to a method call
      // that will also know about permanent highlight stack
      when (line == 35)
      {
        assert(true);
      }
      
      def colorNumToColor(colorNumber)
      {
        | 0 => ScanTokenColor.HighlightOne;
        | 1 => ScanTokenColor.HighlightTwo;
        | _ => assert(false, $"colorNumToColor(colorNumber) failed: colorNumber = $colorNumber")
      }
      def isIntersect(loc1, loc2) { !loc1.Intersect(loc2).IsEmpty }
      def flaten[T](lst : list[T * T]) : list[T]
      {
        | (x1, x2) :: xs => x1 :: x2 :: flaten(xs)
        | [] => []
      }
      def isIntersectWithMainTokenLocation(loc, _) { isIntersect(tokLoc, loc) }
      def lineHighlights = GetHighlightsForLine(line);

      when (!lineHighlights.Exists(isIntersectWithMainTokenLocation))
        return;

      // Отфильтровываем подсвечиваемые области пересекающиеся с текущим токеном
      // и преобразуем список в список типа (цвет * начало-диапазона * конец-диапазона).
      def overlappingRanges = (tocColor, tokLoc.StartPoint(), tokLoc.EndPoint()) 
        :: GetHighlightsForLine(line).MapFiltered(
            isIntersectWithMainTokenLocation,
            (loc, color) => (colorNumToColor(color), loc.StartPoint(), loc.EndPoint()));
          
      def inc(point) { point }
      def dec(point) { point }
      // Преобразуем пересекающиеся диапазоны в список диапазонов непересекающихся
      // между собой (идущий последовательно).
      def flatenRanges = Utils.Utils.RemoveOverlapping(overlappingRanges, inc, dec);
      
      def setTokenInfo(tokInf, (color, start, end))
      {
        def loc = Location(tokLoc, start.Line, start.Column, end.Line, end.Column);
        tokInf.Token = Token.Identifier("");
        tokInf.Color = color;
        tokInf.Token.Location = loc;
        tokInf
      }
      
      // Преобразуем диапазоны в токены с соответствующими Location-ами и добавляем
      // токены в список ожидаемых токенов (_pendingTokens).
      foreach (range in flatenRanges.Tail)
        _pendingTokens.Add(setTokenInfo(tokenInfo.Clone(), range));
      
      // Первый токен приходится явно измнить, задав ему значения из головы списка.
      _ = setTokenInfo(tokenInfo, flatenRanges.Head);
    }

    GetHighlightsForLine(line : int) : list[Location * int]
    {
      def mergeWithResult(result, newValue)
      {
      
        match(newValue)
        {
          | x :: xs => result.Add(x); mergeWithResult(result, xs);
          | _ => ();
        }
      }
      
      // Getting hovered highlights
      def result = SCG.List();
      when (_hoverHighlightedLocations != null)
        mergeWithResult(result, _hoverHighlightedLocations.GetValueOrDefault(line, null));
      
      // Getting permanent highlights
      foreach(stackedHighlight in _permanentHighlights)
        mergeWithResult(result, stackedHighlight.GetValueOrDefault(line, null));
      
      result.NToList();
    }
    
    public SetHoverHighlights(highlights : IEnumerable[GotoInfo]) : void
    {
      def highlights = highlights.Map(h => if (h.UsageType == UsageType.Usage) (h.Location, 0) else (h.Location, 1));

      // TODO: ask why i cannot use the commented form
      //def _ = highlights.Group((one, two) => one[0].Line - two[1].Line);
      def groups = highlights.Group((one : Location * int, two : Location * int) =>
        {
          def (locationOne, _) = one;
          def (locationTwo, _) = two;
          locationOne.Line - locationTwo.Line
        }).Map(locationsOnTheLine => (locationsOnTheLine.Head[0].Line,

      // TODO: find an appropriate place to pass a file index in the lexer, zero is inappropriate
      locationsOnTheLine.Map((l, color) => (Location(0, l.Line, l.Column, l.EndLine, l.EndColumn), color))));

      unless (groups.IsEmpty)
      {
        //def (first, _) = highlights.Head;
        //base.file_idx = first.FileIndex;  // HACK: otherwise it == 0
        def newMap = Hashtable();

        foreach ((line, lineHighlihgts) in groups)
          newMap[line] = lineHighlihgts;

        _hoverHighlightedLocations = newMap;
      }
    }
    
    public AddHighlighting(highlights : IEnumerable[GotoInfo]) : void
    {
      def highlights = highlights.Map(h => if (h.UsageType == UsageType.Usage) (h.Location, 0) else (h.Location, 1));

      def groups = highlights.Group(
      (one : Location * int, two : Location * int) =>
      {
        def (locationOne, _) = one;
        def (locationTwo, _) = two;

        locationOne.Line - locationTwo.Line
      }).Map(locationsOnTheLine => 
        (locationsOnTheLine.Head[0].Line, locationsOnTheLine.Map(
          (l, color) => (Location(0, l.Line, l.Column, l.EndLine, l.EndColumn), color))));

      unless (groups.IsEmpty)
      {
        def newHighlight = Hashtable();
        foreach ((line, lineHighlihgts) in groups)
          newHighlight[line] = lineHighlihgts;
        _permanentHighlights ::= newHighlight;
      }
    }
    
    public RemoveLastHighlighting() : void
    {
      _ = ClearHoverHighlights();

      // Popping last permanent highlighting.
      match(_permanentHighlights)
      {
        | _ :: xs => _permanentHighlights = xs;
        | _ => ()
      } 
    }
    
    public ClearHoverHighlights() : bool
    {
      def cleared = _hoverHighlightedLocations != null;
      _hoverHighlightedLocations = null;
      cleared
    }

    _debug(obj : object) : void
    {
      when (obj != null)
      _ = obj.ToString();
    }
  } // ScanLexer class
}
